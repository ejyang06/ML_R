---
output: html_document
---
Name:Elva Yang
Purpose/Project: Understand the profile of the high-utilizing member and  predict which members are most likely to be among the top 1% of utilizers. ã€€
Dataset: Datset containing over 140 utilization, diagnosis, membership, geographic, and demographic parameters.
knitr 
@ R version 3.1.2

```{r}

rm(list = ls())
library(h2o)
h2o.removeAll() # Clean slate 
library(h2oEnsemble)  # Tload the `h2o` R package 
library(cvAUC) # cross validation AUC
localH2O = h2o.init(ip = '172.16.14.123', port = 54321,strict_version_check= FALSE)


# Load into h2o
attach("/hu/input/hu.RData")
hutrain_hex = as.h2o(hutrain)
hutest_hex = as.h2o(hutest)
y = "hu_01"
hutrain_hex[,y] <- as.factor(hutrain_hex[,y])
x <- hutrain_hex[,-c(145)]
x <- setdiff(names(x), y)

#str(x)
#str(y)

##########################################################################################################
# Splitting into training and test datasets
##########################################################################################################

trainrows =nrow(hutrain)/3 # 2/3 train and 1/3 validation
train = subset(hutrain,mbr_id>=trainrows )
val = subset(hutrain,mbr_id<trainrows)


##########################################################################################################
#Initialize h2o
##########################################################################################################

# Load into h2o
train_hex = as.h2o(train)
val_hex = as.h2o(val)
test_hex = as.h2o(hutest)

# Random Forest - for getting important variables
hu.rf = h2o.randomForest(y = y, x = x, training_frame = train_hex)

# fit the model with important variables. 
impvariables = h2o.varimp(hu.rf)
View(impvariables)

## The response is encoded as factor for binary classification
train_hex[,y] <- as.factor(train_hex[,y]) 

# selecting the 12 more important variables 

x12 = c("pri_cst","ethnct_ds_tx","dx_prspct_med_risk_qt","rx_prspct_ttl_risk_qt","mcare_prspct_med_risk_qt","loh_prspct_qt","cms_hcc_130_ct",
        "rx_inpat_prspct_ttl_risk_qt","cg_2014","cops2_qt","rx_prspct_ttl_risk_qt_p","mcare_prspct_med_risk_qt_p")

# 4 learners
h2o.glm <- function(..., alpha = 0.5, family="binomial", max_iterations = 500, missing_values_handling = "MeanImputation") h2o.glm.wrapper(..., alpha = alpha,missing_values_handling = missing_values_handling,max_iterations=max_iterations, family = family)

h2o.randomForest <- function(..., ntrees = 200, nbins = 50, balance_classes = TRUE, seed = 214) h2o.randomForest.wrapper(..., ntrees = ntrees, nbins = nbins, balance_classes = balance_classes, seed = seed)

h2o.gbm <- function(..., ntrees = 100, balance_classes = TRUE, seed = 214) h2o.gbm.wrapper(..., ntrees = ntrees, balance_classes = balance_classes, seed = seed)

h2o.deeplearning <- function(..., hidden = c(500,500), activation = "Rectifier", epochs = 50, seed = 214)  h2o.deeplearning.wrapper(..., hidden = hidden, activation = activation, seed = seed)


##########################################################################################################
GBM_learner <- c(
   "h2o.glm"
  ,"h2o.randomForest"
  ,"h2o.gbm"
  ,"h2o.deeplearning"
  
)

metalearner <- "h2o.glm.wrapper"

GBM_customfit <- h2o.ensemble(x = x12, y = y,
                              training_frame = train_hex,
                              family='binomial',
                              learner = GBM_learner,
                              metalearner =metalearner,
                              cvControl = list(V = 5))

##########################################################################################################
#Check on Validation datasets
GBM_valpred <- predict(GBM_customfit, val_hex)

#third column is P(Y==1)
GBM_valpredictions <- as.data.frame(GBM_valpred$pred)[,3]
labels <- as.data.frame(val_hex[,y])[,1]

#AUC expected
cvAUC::AUC(predictions = GBM_valpredictions, labels = labels)


# Check how each learner did, tuning the parameters in the future
L <- length(GBM_learner)
auc <- sapply(seq(L), function(l) cvAUC::AUC(predictions = as.data.frame(GBM_valpred$basepred)[,l], labels = labels)) 
data.frame(GBM_learner, auc)


# Generate predictions on the test set:
GBM_pred <- predict(GBM_customfit, test_hex)
GBM_predictions <- as.data.frame(GBM_pred$pred)[,3]


#Creating a output
output_data <- function(id,predictions,filename)
{ 
  output<-cbind(id,predictions)
  colnames(output) <- c("mbr_id", "prediction")
  output <- as.data.frame(output) 
  filename = paste0("/hu/output/ID_123",filename,"ID_123.csv")
  write.csv(output, filename,row.names = FALSE)
}

output_data(hutest$mbr_id,GBM_predictions,"output_model") 


```
